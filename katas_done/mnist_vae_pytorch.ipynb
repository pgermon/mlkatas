{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a self-correcting activity generated by [nbgrader](https://nbgrader.readthedocs.io). Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Run subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate handwritten digits with a VAE (PyTorch)\n",
    "\n",
    "The goal here is to train a VAE to generate handwritten digits.\n",
    "\n",
    "![VAE digits](images/vae_digits.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.4.0\n",
      "device =  cpu\n"
     ]
    }
   ],
   "source": [
    "# Import ML packages (edit this list if needed)\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Create batch data loaders `trainloader` and `testloader` resp. for training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3af1c62cd8f2c6b61d53831111324fed",
     "grade": true,
     "grade_id": "cell-7ee6e64de897e788",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# YOUR CODE HERE\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "### Question\n",
    "\n",
    "Complete the following class to create a variational autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a41ad65b45e378060e1180f987522c1",
     "grade": true,
     "grade_id": "cell-aeffbaacaac863dc",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input into its latent representation\n",
    "        Returns mean and standard deviation\"\"\"\n",
    "        \n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def sample(self, mu, log_var):\n",
    "        \"\"\"Sample a random codings vector from a gaussian distribution\n",
    "        Takes mean and log_var (gamma) as parameters\"\"\"\n",
    "        \n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode codings\"\"\"\n",
    "        \n",
    "        h = F.relu(self.fc4(z))\n",
    "        return torch.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Encode inputs to obtain mean and standard deviation\n",
    "           Sample codings from gaussian distribution using mean and std\n",
    "           Returns decoded codings, mean and standard deviation\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        mu, log_var = self.encode(x)\n",
    "        sampled = self.sample(mu, log_var)\n",
    "        decoded = self.decode(sampled)\n",
    "        return decoded, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "### Question\n",
    "\n",
    "Complete the following training loop to:\n",
    "- instantiate the variational autoencoder on target device.\n",
    "- instanciate the Adam optimizer.\n",
    "- implement forward pass and gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1aa733bf1670de1f6f642ffc6c3dcfdf",
     "grade": true,
     "grade_id": "cell-11f1ec283e7cd535",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], step [469/469], reconst loss: 9645.1650, KL div: 2002.2250\n",
      "Epoch [2/15], step [469/469], reconst loss: 8252.0947, KL div: 2194.8657\n",
      "Epoch [3/15], step [469/469], reconst loss: 8215.7480, KL div: 2345.3354\n",
      "Epoch [4/15], step [469/469], reconst loss: 8252.9414, KL div: 2338.0591\n",
      "Epoch [5/15], step [469/469], reconst loss: 7969.6001, KL div: 2369.6467\n",
      "Epoch [6/15], step [469/469], reconst loss: 8530.3330, KL div: 2452.9790\n",
      "Epoch [7/15], step [469/469], reconst loss: 7970.4634, KL div: 2365.6082\n",
      "Epoch [8/15], step [469/469], reconst loss: 7711.5215, KL div: 2486.0381\n",
      "Epoch [9/15], step [469/469], reconst loss: 7952.0791, KL div: 2383.5613\n",
      "Epoch [10/15], step [469/469], reconst loss: 7854.0146, KL div: 2466.0996\n",
      "Epoch [11/15], step [469/469], reconst loss: 8159.8701, KL div: 2370.4321\n",
      "Epoch [12/15], step [469/469], reconst loss: 7377.4419, KL div: 2415.7322\n",
      "Epoch [13/15], step [469/469], reconst loss: 7571.5806, KL div: 2408.0161\n",
      "Epoch [14/15], step [469/469], reconst loss: 7684.7349, KL div: 2481.4751\n",
      "Epoch [15/15], step [469/469], reconst loss: 7780.7881, KL div: 2420.8154\n"
     ]
    }
   ],
   "source": [
    "input_dim = 784\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "num_epochs = 15\n",
    "learning_rate = 1e-3\n",
    "prints_per_epoch = 1  # Increase to see more feedback during training\n",
    "\n",
    "# Instanciate VAE and optimizer\n",
    "# YOUR CODE HERE\n",
    "vae = VAE(input_dim, hidden_dim, latent_dim)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(trainloader):\n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE\n",
    "        x = x.to(device).view(-1, input_dim)\n",
    "        x_reconst, mu, log_var = vae(x) #appel implicite à la méthode forward\n",
    "\n",
    "        # Compute reconstruction loss and KL divergence\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction=\"sum\")\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        loss = reconst_loss + kl_div\n",
    "\n",
    "        # Backprop and optimize\n",
    "        # YOUR CODE HERE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print losses at regular intervals\n",
    "        step_count = len(trainloader)\n",
    "        print_threshold = math.ceil(step_count / prints_per_epoch)\n",
    "        if (i + 1) % print_threshold == 0 or (i + 1) == step_count:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}]\"\n",
    "                f\", step [{i + 1}/{step_count}]\"\n",
    "                f\", reconst loss: {reconst_loss.item():.4f}\"\n",
    "                f\", KL div: {kl_div.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructions visualization¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image.numpy().squeeze(), cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_reconstructions(model, images, n_images=8):\n",
    "    \"\"\"Show original and reconstructed images side-by-side\"\"\"\n",
    "    \n",
    "    inputs = images.reshape(-1, 28*28).to(device)\n",
    "    reconstructions, _, _ = model(inputs)\n",
    "    \n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index].view(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Show reconstructions for one batch of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "010911be05113bb3a62264e3800a0e1f",
     "grade": true,
     "grade_id": "cell-6927b3114069f46f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_reconstruction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-93ffdc969cb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mshow_reconstruction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'show_reconstruction' is not defined"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "dataiter = iter(testloader)\n",
    "images, _ = dataiter.next()\n",
    "with torch.no_grad():\n",
    "    show_reconstruction(vae, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new images¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_images(images, n_cols=None):\n",
    "    \"\"\"Show a series of images\"\"\"\n",
    "\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols * 1.5, 3))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image.numpy().squeeze(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Use the VAE to show several generated digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb4b694aae1da7ed57a3c2d7ba1a3134",
     "grade": true,
     "grade_id": "cell-58f40750d5551290",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(16, latent_dim).to(device)\n",
    "    # YOUR CODE HERE\n",
    "    gen_images = vae.decode(z).view(-1, 1, 28, 28)\n",
    "    plot_multiple_image(gen_images, n_cols=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
